{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "VIX = pd.read_csv('data/VIX.csv', header = 2)\n",
    "DOW = pd.read_csv('data/DOW.csv', header = 2)\n",
    "GFD = pd.read_csv('data/GFD_TBILL_DAILY.csv', header = 2)\n",
    "GOLD = pd.read_csv('data/GOLD.csv', header = 2)\n",
    "SPX = pd.read_csv('data/SPX.csv', header = 2)\n",
    "# I'm not using US_10YR because it contains duplicate values for many dates\n",
    "#US_10YR = pd.read_csv('data/US_10yr_yield.csv', header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>VIX</th>\n",
       "      <th>DOW</th>\n",
       "      <th>GFD</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>-0.030988</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>-0.013376</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>-0.037400</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.007408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.002708</td>\n",
       "      <td>0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84264</th>\n",
       "      <td>1791-02-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84265</th>\n",
       "      <td>1791-02-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84266</th>\n",
       "      <td>1791-02-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>1791-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84268</th>\n",
       "      <td>1791-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84269 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       VIX       DOW       GFD      GOLD       SPX\n",
       "0     2021-10-21 -0.030988 -0.000176  0.000002       NaN  0.003069\n",
       "1     2021-10-20 -0.013376  0.004288  0.000001 -0.000871  0.003675\n",
       "2     2021-10-19 -0.037400  0.005636  0.000001  0.006618  0.007408\n",
       "3     2021-10-18  0.000613 -0.001024  0.000002 -0.002708  0.003375\n",
       "4     2021-10-17       NaN       NaN  0.000002       NaN       NaN\n",
       "...          ...       ...       ...       ...       ...       ...\n",
       "84264 1791-02-05       NaN       NaN  0.000164       NaN       NaN\n",
       "84265 1791-02-04       NaN       NaN  0.000164       NaN       NaN\n",
       "84266 1791-02-03       NaN       NaN  0.000164       NaN       NaN\n",
       "84267 1791-02-02       NaN       NaN  0.000164       NaN       NaN\n",
       "84268 1791-02-01       NaN       NaN       NaN       NaN       NaN\n",
       "\n",
       "[84269 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a helper function to process the data\n",
    "def process_data(df, label, pct_change = True):\n",
    "    \n",
    "    # Convert the Date column from a string to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Get only the Dates earlier than 2021-10-21 since we aren't predicting into the future\n",
    "    df = df.loc[(df['Date'] <= '2021-10-21')]\n",
    "    \n",
    "    # Carries forward old prices, so we aren't using future information\n",
    "    df.fillna(method = 'ffill', inplace=True) \n",
    "    \n",
    "    # Drop the 'Ticker' and 'Open' columns\n",
    "    df = df.drop(columns = ['Ticker', 'Open'], axis=1)\n",
    "    \n",
    "    # Take percentage changes\n",
    "    if pct_change == True:\n",
    "        df.loc[:, 'Close'] = df.loc[:, 'Close'].pct_change()\n",
    "    \n",
    "    # Reverse the data to go backward in time\n",
    "    df = df.sort_values(by='Date', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Rename the 'Close' column with the passed label\n",
    "    df = df.rename(columns={'Close': label})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process all of the data\n",
    "VIX = process_data(VIX, 'VIX')\n",
    "DOW = process_data(DOW, 'DOW')\n",
    "GFD = process_data(GFD, 'GFD')\n",
    "GOLD = process_data(GOLD, 'GOLD')\n",
    "SPX = process_data(SPX, 'SPX')\n",
    "#US_10YR = process_data(US_10YR, 'US_10YR')\n",
    "\n",
    "\n",
    "# Merge all of the data into one large dataframe\n",
    "from functools import reduce\n",
    "\n",
    "dfs = [VIX, DOW, GFD, GOLD, SPX]\n",
    "#dfs = [VIX, DOW, GFD, GOLD, SPX, US_10YR]\n",
    "data = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), dfs)\n",
    "\n",
    "# Sort the data by descending date\n",
    "data = data.sort_values(by='Date', ascending=False).reset_index(drop=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot('Date', subplots=True, figsize = (15,20))\n",
    "plt.show()\n",
    "\n",
    "data['VIX'].plot(kind = 'kde', figsize = (15,4), title = 'VIX Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_data_processing(data, start_date, end_date, n_time_steps = 90, include_vix = True):\n",
    "\n",
    "    # Get the indices of the start date and the end date\n",
    "    start_index = int(np.where(data[:,0] == pd.to_datetime(start_date))[0])\n",
    "    end_index = int(np.where(data[:,0] == pd.to_datetime(end_date))[0])\n",
    "    \n",
    "    # Flag to set if VIX data is included in the training set\n",
    "    if include_vix:\n",
    "        # Get all of the input data (X)\n",
    "        X_data = data[:,1:].astype('float32')\n",
    "    else:\n",
    "        # Get all of the input data (X)\n",
    "        X_data = data[:,2:].astype('float32')   \n",
    "    \n",
    "    # Create an empty array to store the restructured input data\n",
    "    X_data_extended = np.zeros((X_data.shape[0], n_time_steps, X_data.shape[-1]))\n",
    "\n",
    "    # Loop through all samples \n",
    "    for i in range(start_index, end_index+1):\n",
    "        X_data_extended[i] = X_data[i-n_time_steps:i,:]\n",
    "    \n",
    "    # Get all of the input data (X) for the desired date range\n",
    "    X_data = X_data_extended[start_index:end_index+1]\n",
    "\n",
    "    # Get all of the output data (Y) for the desired date range\n",
    "    y_data = data[start_index:end_index+1,1].astype('float32')\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "# Define a function to process the data for Bidirectional LSTM\n",
    "def bidirectional_data_processing(data, start_date, end_date, n_time_steps = 30):\n",
    "\n",
    "    # Get the indices of the start date and the end date\n",
    "    start_index = int(np.where(data[:,0] == pd.to_datetime(start_date))[0])\n",
    "    end_index = int(np.where(data[:,0] == pd.to_datetime(end_date))[0])\n",
    "    \n",
    "    # Get all of the input data (X)\n",
    "    X_data = data[:,2:].astype('float32')\n",
    "    \n",
    "    # Create an empty array to store the restructured input data\n",
    "    X_data_extended = np.zeros((X_data.shape[0], 2*n_time_steps+1, X_data.shape[-1]))\n",
    "\n",
    "    # Loop through all samples \n",
    "    for i in range(start_index, end_index+1):\n",
    "        X_data_extended[i] = X_data[i-n_time_steps:i+n_time_steps+1,:]\n",
    "    \n",
    "    # Get all of the input data (X) for the desired date range\n",
    "    X_data = X_data_extended[start_index:end_index+1]\n",
    "\n",
    "    # Get all of the output data (Y) for the desired date range\n",
    "    y_data = data[start_index:end_index+1,1].astype('float32')\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "# Convert the data from a pandas dataframe to a numpy array\n",
    "np_data = data.to_numpy()\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = np_data.copy()\n",
    "scaled_data[:,1:] = scaler.fit_transform(scaled_data[:,1:])\n",
    "\n",
    "# Define the number of timesteps to look forward and backward (total number of timesteps is 2*n_timesteps+1)\n",
    "n_time_steps = 90\n",
    "\n",
    "# Split data into train, dev, and test sets\n",
    "X_train, y_train = lstm_data_processing(scaled_data, start_date = '12/31/2020', end_date = '01/01/1991', n_time_steps = n_time_steps, include_vix = False)\n",
    "X_dev, y_dev = lstm_data_processing(scaled_data, start_date = '12/31/1990', end_date = '07/01/1988', n_time_steps = n_time_steps, include_vix = False)\n",
    "X_test, y_test = lstm_data_processing(scaled_data, start_date = '06/30/1988', end_date = '01/01/1986', n_time_steps = n_time_steps, include_vix = False)\n",
    "\n",
    "# Verify the shapes of the input and output data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "lstm_model = Sequential()\n",
    "\n",
    "# Adding a Bidirectional LSTM layer\n",
    "lstm_model.add(LSTM(64, return_sequences=False, dropout=0.5, input_shape=(X_train.shape[1], X_train.shape[-1])))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "lstm = lstm_model.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and dev losses over epoch\n",
    "plt.plot(lstm.history['loss'], label='train')\n",
    "plt.plot(lstm.history['val_loss'], label='dev')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the training and dev sets\n",
    "y_train_hat = lstm_model.predict(X_train)\n",
    "y_dev_hat = lstm_model.predict(X_dev)\n",
    "\n",
    "# Showing the predicted vs. actual values\n",
    "fig, axs = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "axs.plot(y_train_hat, color='red', label='Predicted')\n",
    "axs.plot(y_train, color='blue', label='Actual')\n",
    "plt.title('Training Set')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Scaled VIX')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "axs.plot(y_dev_hat, color='red', label='Predicted')\n",
    "axs.plot(y_dev, color='blue', label='Actual')\n",
    "plt.title('Dev Set')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Scaled VIX')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
